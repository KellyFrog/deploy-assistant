# Deploy-Assistant

借助 LLM 和终端交互完成项目自动部署/安装。

大概的工作流程和要实现的东西：

- 终端部分：实现一个模拟终端，终端类模拟/和一个 powershell 交互，支持输入一条命令，返回它的输出（stdout 和 stderr）
- LLM 调用集成模块：实现一个 LLM 交互封装类，封装和 API/本地模型 交互的过程。
- Prompt 工程：
  - 设计整个和 LLM 交互流程中的 Prompt，应当先确定交互流程。
- Agent 模块：
  - 允许部分和本地文件交互（这个如果只实现一件部署可能不是特别需要）。
  - 可能可以实现计划功能，让 LLM 先做整体计划然后分布进行（这样可扩展性强一点，可能可以迁移到其他功能）。
- 记忆模块：给 LLM 提示告诉他现在在干什么/已经干了什么。
- 安全模块：实现一个函数，区别安全和危险指令（用户可以选择默认执行安全指令，但危险指令必须手动确认）。
- 应用后端：实现一个类，表示当前整个运行流程的对象，供前端调用。
- 应用前端：可以先写 CLI，剩下的之后再说。

现在已经实现/已经认领的任务：

- 终端部分：已经初步写完，但是比较粗糙，感觉当一个玩具已经够了
- 剩下的都没写。

现在比较紧急的任务：

- 确定和 LLM 交互的整个流程以及通过外部工具实现的功能，它应当大体包括：
  - 环境检测：首先让 LLM 看看需要装什么应用（如 cmake、cargo、npm 等命令行工具是否安装），这可能直接集成一些效率会高一点。
  - 命令分解：让 LLM 确定每一个步骤和一条命令。
  - 问题检测：运行完命令后，将内容返回给 LLM 检查运行是否符合预期。
  - 修复问题：在这一个步骤当中解决这一个步骤的问题，同样返回当前的命令。
  - 问题决策：有一些问题需要让用户决策，如使用 MSVC 还是 MinGW 编译、使用 Qt5 还是 Qt6、用哪个 conda 环境 / python 版本等，这些问题不适合让 AI 决定，应当有交互的过程。

已经规划好的任务：
- 实现一个包装好的 LLM 类，包括 Prompt、附加文件、流式返回等功能

推荐试用一下 vscode 的 cline 插件，看别人的 agent 写成了啥样，看看那些地方会遇到问题（主要是遇到依赖问题根本不检测/反复重装环境、交互速度慢），针对部署这一专门需求设计 Prompt。